# Monitoring
Vamos a simular algunos servidores utilizando LXC y Docker containers, así que hay que instalar y configurar LXC y Docker como se explicó en la práctica 1.

## Servidores simulados
### LXC
```
lxc init ubuntu:16.04 host00
lxc config device add host00 eth0 nic name=eth0 nictype=bridged parent=lxdbr0
lxc config device set host00 eth0 ipv4.address 10.0.100.100

lxc start host00
```
Nos conectamos a `host00`
```
lxc exec host00 -- /bin/bash
apt update
apt upgrade -y
```
y ejecutamos estos comandos para instalar el software que necesitaremos durante la práctica:

```
# Instalación de Node Exporter
sudo useradd --no-create-home --shell /bin/false node_exporter

wget https://github.com/prometheus/node_exporter/releases/download/v0.16.0-rc.1/node_exporter-0.16.0-rc.1.linux-amd64.tar.gz
tar xzf node_exporter-0.16.0-rc.1.linux-amd64.tar.gz
sudo cp node_exporter-0.16.0-rc.1.linux-amd64/node_exporter /usr/local/bin/

cat <<EOF | sudo tee /etc/systemd/system/node_exporter.service
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/usr/local/bin/node_exporter

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl daemon-reload
sudo systemctl enable node_exporter
sudo systemctl start node_exporter
```
Node Exporter escucha en el puerto 9100. Podemos ejecutar los siguientes comandos para comprobar que está escuchando y ver la lista de métricas que proporciona cuando un servidor Prometheus le consulta:
```
ss -nlt
curl http://localhost:9100/metrics
```
Seguimos con la instalación de Telegraf:
```
wget https://dl.influxdata.com/telegraf/releases/telegraf_1.5.3-1_amd64.deb
dpkg -i telegraf_1.5.3-1_amd64.deb
systemctl status telegraf
systemctl stop telegraf
```
Editar el fichero `/etc/telegraf/telegraf.conf` y cambiar la url en la sección `[[outputs.influxdb]]` para que apunte `http://10.0.100.1:8086`. Aquí estará escuchando InfluxDB, que instalaremos más tarde en el host principal.

Finalmente, instalamos `collectd`:
```
sudo apt install -y collectd
```
y configuramos este servicio: hay que editar el fichero `/etc/collectd/collectd.conf` realizar los siguientes cambios para cargar y configurar el plugin 'network':
```
LoadPlugin network
....
<Plugin network>
        Server "10.0.100.1" "25826"
</Plugin>
```
Salimos del contenedor `host00`:
```
exit
```
y realizamos dos copia, para simular más servidores:
```
lxc copy host00 host01
lxc config device set host01 eth0 ipv4.address 10.0.100.101

lxc copy host00 host02
lxc config device set host02 eth0 ipv4.address 10.0.100.102

lxc start host01 host02
```

## Prometheus

```
# Creación del usuario que usaremos para correr el proceso de prometheus
sudo useradd --no-create-home --shell /bin/false prometheus

# Directorios para almacenar la configuración y los datos de prometheus
sudo mkdir /etc/prometheus
sudo mkdir /var/lib/prometheus
sudo chown prometheus:prometheus /etc/prometheus
sudo chown prometheus:prometheus /var/lib/prometheus

wget https://github.com/prometheus/prometheus/releases/download/v2.2.1/prometheus-2.2.1.linux-amd64.tar.gz
tar xzf prometheus-2.2.1.linux-amd64.tar.gz
sudo cp prometheus-2.2.1.linux-amd64/prometheus /usr/local/bin/
sudo cp prometheus-2.2.1.linux-amd64/promtool /usr/local/bin/
sudo chown prometheus:prometheus /usr/local/bin/prometheus
sudo chown prometheus:prometheus /usr/local/bin/promtool
sudo cp -r prometheus-2.2.1.linux-amd64/consoles /etc/prometheus
sudo cp -r prometheus-2.2.1.linux-amd64/console_libraries /etc/prometheus
sudo chown -R prometheus:prometheus /etc/prometheus/consoles
sudo chown -R prometheus:prometheus /etc/prometheus/console_libraries
```
Configuración de Prometheus, para monitorizarse a si mismo y los hosts que estamos simulando con LXC:
```
cat <<EOF | sudo tee /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:9090']
  - job_name: 'node_exporter'
    scrape_interval: 5s
    static_configs:
      - targets: ['10.0.100.1:9100', '10.0.100.100:9100', '10.0.100.101:9100', '10.0.100.102:9100']
EOF

sudo chown prometheus:prometheus /etc/prometheus/prometheus.yml
```
Creamos la configuración para el servicio de Prometheus y lo arrancamos:
```
cat <<EOF | sudo tee /etc/systemd/system/prometheus.service
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
    --config.file /etc/prometheus/prometheus.yml \
    --storage.tsdb.path /var/lib/prometheus/ \
    --web.console.templates=/etc/prometheus/consoles \
    --web.console.libraries=/etc/prometheus/console_libraries

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl daemon-reload
sudo systemctl enable prometheus
sudo systemctl start prometheus
```
Ejecutar los siguientes comandos para comprobar que Prometheus está funcionando correctamente:
```
sudo systemctl status prometheus
```
Desde un navegador, visitar: `http://<ip>:9090/`

En la web de Prometheus, ejecutar los siguientes pasos:
```
Go to Status/Targets
Go to Graph
In Expression, type node_memory_MemAvailable_bytes. Click on Execute button.
We will see in Console the memory available in host00, host01 and host02
To have the memory in MB, execute the expression node_memory_MemAvailable_bytes/1024/1024
Execute 'free -h' in one of the hosts to verify that the value reported is right, e.g. "lxc exec host00 -- free -h"
Execute expression "avg_over_time(node_memory_MemAvailable[5m])/1024/1024". Click on Graph
```
La web de Prometheus es extremadamente simple. Lo recomendable es usar Grafana para visualizar los datos almacenados por Prometheus.

## Grafana
Instalamos Grafana
```
wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana_5.0.4_amd64.deb
sudo apt install -y libfontconfig1
sudo dpkg -i grafana_5.0.4_amd64.deb

sudo systemctl daemon-reload
sudo systemctl enable grafana-server
sudo systemctl start grafana-server
```
Go to Grafana web: `http://<ip>:3000`
```
Login: admin/admin
First time: click on Add data source
Later: Go to Configuration > Data sources. Then, Add data source.
    Name: prometheus
    Type: Prometheus
    URL: http://localhost:9090
    Access: proxy
    Scrape interval: 15s
    Save & Test
```

Ahora crearemos algunos dashboards.

### Grafana Dashboards (Prometheus)

## Monitorización de Docker Containers con Prometheus
Google ha desarrollado cAdvisor (https://github.com/google/cadvisor), que permite que Prometheus acceda a estadísticas sobre el funcionamiento de los contenedores que tenemos corriendo en nuestro servidor.

Podemos ejecutar cAdvisor también dentro de un contenedor:
```
docker run \
  --volume=/:/rootfs:ro \
  --volume=/var/run:/var/run:rw \
  --volume=/sys:/sys:ro \
  --volume=/var/lib/docker/:/var/lib/docker:ro \
  --volume=/dev/disk/:/dev/disk:ro \
  --publish=8080:8080 \
  --detach=true \
  --name=cadvisor \
  google/cadvisor:latest
```
Añadir lo siguiente a la configuración de Prometheus, para que obtenga también métricas de cAdvisor:
```
  - job_name: 'cadvisor'
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:8080']
```
y rearrancar el servicio:
```
sudo systemctl restart prometheus
```
En lugar de crear nuestro propio dashboard para monitorizar los contenedores, vamos a utilizar uno de los ya existentes, publicados en https://grafana.com/dashboards. Elegir 'Docker Host & Container Overview'.

Descargar el fichero json e importarlo en nuestro Grafana.

Ya tendremos un contenedor, cAdvisor, pero podemos lanzar alguno más. En diferentes terminales, ejecutar estos comandos:
```
# Terminal 1
docker run --name dc00 -it  alpine /bin/sh

# Terminal 2
docker run --name dc01 -it  alpine /bin/sh
```
y para que haya algo de consumo de cpu, ejecutar en esos contenedores algún comando como el siguiente:
```
while [ true ] ; do sum=$(( 1 + 1 )) ; done
```
Veremos la actividad de los contenedores reflejada en el nuevo dashboard.

## TICK Stack
Instalamos los diferentes componentes de TICK Stack en nuestro servidor:
### InfluxDB
```
wget https://dl.influxdata.com/influxdb/releases/influxdb_1.5.1_amd64.deb
sudo dpkg -i influxdb_1.5.1_amd64.deb

sudo systemctl status influxdb
sudo systemctl start influxdb
```
## Telegraf
```
wget https://dl.influxdata.com/telegraf/releases/telegraf_1.5.3-1_amd64.deb
sudo dpkg -i telegraf_1.5.3-1_amd64.deb

sudo usermod -aG docker telegraf

sudo systemctl status telegraf
sudo systemctl stop telegraf
```
Editar `/etc/telegraf/telegraf.conf` y descomentar `docker`:
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
  container_names = []
  container_name_include = []
  container_name_exclude = []
  timeout = "5s"
  perdevice = true
  docker_label_include = []
  docker_label_exclude = []
```
Después arrancar Telegraf:
```
sudo systemctl start telegraf
```
Consultar  https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf
para hacerse una idea de la variedad de inputs and outputs que soporta Telegraf.

### Kapacitor
```
wget https://dl.influxdata.com/kapacitor/releases/kapacitor_1.4.1_amd64.deb
sudo dpkg -i kapacitor_1.4.1_amd64.deb

sudo systemctl start kapacitor
kapacitor list tasks
```

### Chronograf
```
wget https://dl.influxdata.com/chronograf/releases/chronograf_1.4.3.1_amd64.deb
sudo dpkg -i chronograf_1.4.3.1_amd64.deb

sudo systemctl status chronograf
```

### InfluxDB CLI
Podemos interactuar directament con InfluxDB desde la línea de comandos:
```
influx
```
Probar algunos comandos, como los siguientes:
```
> show databases
> use telegraf
> show measurements

> show tag keys from cpu
> show tag values from cpu with key = host
> show tag values from cpu with key = cpu

> show tag keys from docker_container_cpu
> show tag values from docker_container_cpu with key = container_name

> select * from docker_container_cpu where container_name = 'dc00'
```

### Using Chronograf
Ir a la web de Chronograf: `http://<ip>:8888`. Aceptar la creación de la conexión a InfluxDB que se propone al entrar por primera vez.

Explorar la Host List. Navegar por algún host.

En `Data Explorer`:
* Probar el botón Query Templates. Por ejemplo, ejecutar `Show Databases`, `Show Measurements`.
* Crear una query:
```
Retention Policy: telegraf.autogen
Measurements & Tags: docker_container_cpu.cpu.cpu_total (Group By cpu)
                         docker_container_cpu.container_name (Group by container_name)
Fields: usage_percent
```

En `Alerts`:
* Crear una alerta
```
Name: Docker CPU
Time Series: igual que la query anterior
Conditions: value is greater than 140
Alert Handlers: log, /tmp/alerts.log
Message: TS: {{.Time}} - {{.ID}} is {{.Level}} - value:  {{ index .Fields "value" }} -  {{.Group}}
Save
```
* Provocar el fallo ejecutando un proceso que consuma cpu.
* Terminar el uso de cpu y ver que la alarma se limpia

Crear un dashboard.

### Usar Grafana en lugar de chronograf

En Grafana, crear un nuevo data source:
```
Name: influxdb
Type: InfluxDB
URL: http://localhost:8086
Access: proxy
Database: telegraf
Min time interval: 10s
Save & Test
```

Crear dashboards.

### Usar collectd en lugar de telegraf

Instalar `collectd` en el servidor:
```
sudo apt install -y collectd
```
Editar `/etc/influxdb/influxdb.conf` para habilitar el endpoint de `collectd`:
```
[[collectd]]
  enabled = true
  bind-address = ":25826"
  database = "collectd"
  retention-policy = ""
  #
  # The collectd service supports either scanning a directory for multiple types
  # db files, or specifying a single db file.
  typesdb = "/usr/share/collectd"
```
Rearrancar InfluxDB para leer la nueva configuración:
```
sudo systemctl restart influxdb
```
Crear en InfluxDB la base de datos `collectd` que será donde estos procesos vuelquen sus métricas:
```
curl -G http://localhost:8086/query --data-urlencode "q=CREATE DATABASE collectd"
```
Editar `/etc/collectd/collectd.conf` para cargar y configurar el plugin 'network':
```
LoadPlugin network
....
<Plugin network>
        Server "10.0.100.1" "25826"
</Plugin>
```
Instalamos un plugin para que `collectd` también monitorice los contenedores Docker:
```
curl -Ls "https://github.com/dustinblackman/collectd-docker-plugin/releases/download/0.3.0/collectd-docker-plugin-linux-amd64-0.3.0.tar.gz" | sudo tar xz -C /usr/local/bin/
sudo curl -o /usr/share/collectd/docker.db https://raw.githubusercontent.com/dustinblackman/collectd-docker-plugin/master/collectd/docker.db
sudo curl -o /etc/collectd/collectd.conf.d/docker.conf https://raw.githubusercontent.com/dustinblackman/collectd-docker-plugin/master/collectd/docker.conf
sudo usermod -aG docker nobody
```
Y rearrancamos los servicios:
```
sudo systemctl restart influxdb
sudo systemctl restart collectd
```
En Grafana creamos otro data source:
```
Name: influxdb-collectd
Type: InfluxDB
URL: http://localhost:8086
Access: proxy
Database: collectd
Min time interval: 10s
Save & Test
```
y creamos un dashboard.
